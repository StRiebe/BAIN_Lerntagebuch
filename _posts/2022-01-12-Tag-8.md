Im achten Block sollte nun der grosse Paukenschlag stattfinden – nicht meine Emotionalität – aber der Logik der 
Dozenten folgend, wurde in allen vorhergehenden Lehreinheiten darauf zu gearbeitet, heute die MARC21-XML-Dateien 
aus allen vier behandelten Datenquellen mit VuFind zusammenzuführen sie von dort aus herunterladbar zu machen. 
Doch um den Spannungsbogen zu halten, erst einmal noch ein Nachtrag zum Kapitel Metadaten modellieren & Schnittstellen 
nutzen und eine kleine Vertiefung zu Solr und VuFind. 

Heimlich hoffend, dass das vorangegangene Kapitel ausreichend erschöpft wurde, gab es zu Beginn der Lehreinheit einen 
kleinen und zugegebener Massen leicht verdaulichen Nachschlag. Den zwei Blöcken zum Thema Metadaten modellieren & 
Schnittstellen nutzen wurde schliesslich eine Antwort auf die Frage Wofür das Ganze?! nachgereicht. Sicherlich keine 
berufliche Perspektive für mich, aber dennoch interessant bekamen wir einen Einblick in die Tätigkeitsfelder von 
Metadatenexpert:innen oder Metadatenmanager:innen. Sie befassen sich mit Mapping, Analyse von Daten, Datenqualitätsmanagement, 
Frameworks für die Aufbereitung und vielem mehr. Die Expertin Kirsten Jeude, welche uns als Referenz für dieses Berufsfeld 
vorgestellt wurde, ermöglicht z.B. die Zusammenführung von bibliografischen Nachweisen aus verschiedenen Quellen und aus 
unterschiedlichen Formaten. Dafür muss sie sich mit den ganzen Standards der verschiedenen Quellen auskennen und diese zu 
übersetzen wissen um sie schliesslich zusammen zu bringen. Für mich als potentielle Anwenderin ist nun verständlich, dass 
sich Datenmenge und somit Auswahl für mich erheblich vergrössern, wenn ich diese alle aus einer Anwendung oder Software 
heraus erreichen und nutzen kann. 

Open Refine bekam auch wieder einen Auftritt, diesmal jedoch als Nebendarsteller. Ziel war es aufzuzeigen, dass neben Open 
Refine auch andere Tools zur Verfügung stehen. Catmandu und Metafacture sind in anderen Programmiersprachen geschrieben (Perl & Java) 
und operieren nicht mit einer grafischen Oberfläche. Auch MarcEdit wurde als vergleichbare Anwendung aufgeführt. 
Der Hinweis, dass eine Software die man sich gewöhnt hat und die gut beherrscht wird nicht zwingend die geeignete oder 
effizienteste für alle Arbeitsschritte ist, scheint banal, trifft bei mir allerdings einen Nerv. Das Faultier in mir ringt ab und 
zu der «falschen» Software Ergebnisse ab, die mit einem Wechsel zu einer anderen, mir noch nicht vertrauten Software, speditiver 
und häufig in einer kontrollierteren Umgebung zu holen wären.

Weiter ging es mit JSON-API. Die Botschaft von diesem Input sollte wahrscheinlich sein, dass XML-Daten vorwiegend in Archiven und 
Bibliotheken üblich sind und darin auch ihre Berechtigung haben. Im Webkontext ist das JavaScript-kompatible JSON-Format allerdings 
verbreiteter. Die Java Script Object Notation baut auf einer einfacheren Struktur auf. So gibt es jeweils nur eine Bezeichnung für 
ein Feld und den Inhalt des Feldes – diese können nach Bedarf hierarchisch verschachtelt werden.
Wir schauten uns ein Beispiel für eine JSON-API im bibliothekarischen Bereich an: lobid-gnd. Wie der Name schon sagt, geht es hier 
um Normdaten, genauer, um die visuelle Darstellung dieser Daten mit der Option ausserdem einen JSON-Datensatz auszulesen. 
Abgeschlossen wurde das Thema mit scrapir.org. Diese Software ermöglicht den Zugang zu JSON-APIs von verschiedenen Anbieter:innen und 
Web Services. Damit werden Rückgabetabellen und Datenstrukturen von Spotify, Unsplash, Reddit usw. ersichtlich. Für die Datenstruktur 
fehlt allerdings ein einheitlicher Standard, d.h. die Tabellen sind nicht in jedem Fall brauchbar oder nachvollziehbar.

Damit sind wir beim Hauptteil von Block 8 angekommen: Suchmaschinen und Discoverysysteme. Wichtige Erkenntnis Nr. 1 – Solr (Searching On 
Lucene w/ Replication) ist ein weit verbreiteter und essentieller Bestandteil vieler Suchmaschinen und auch ein Kernbestandteil von VuFind. 
Wichtige Erkenntnis Nr. 2: VuFind ist eine freie Bibliothekssoftware, bzw. ein Discoverysystem, oder noch besser, ein bibliothekarisches 
Suchsystem. Alles klar? 
Nun, in Solr werden Suchindizes aufgebaut und es bietet API an, über welche Abfragen laufen können. Solr zeichnet sich unter anderem dadurch 
aus, dass es grosse Datenmengen verarbeiten kann. Auch Solr arbeitet mit Schemata, darin werden Felder und dazugehörige Datentypen für den 
Suchindex festgelegt. Der Solr-Server bietet zwar eine rudimentäre Suchoberfläche für Bearbeitungen auf Administrativebene, wirklich zur 
Anwendung kommt Solr allerdings erst mit zusätzlicher Software, welche auch eine geeignete Nutzer:innenansicht liefert – zum Beispiel VuFind.
Der Solr-Server bietet die Möglichkeit mehrere Indizes, d.h. auch mehrere Datenkerne anzulegen. Bei VuFind gibt es vier davon: Authority, 
Biblio, Reserves und Website. Ein Blick auf die darin angelegten Felder zeigt, dass diese unterschiedlichen Funktionen erfüllen und entsprechend 
mit Parametern versehen sind. Die Parameter bilden verschiedene Kriterien ab, nach denen die Suche durchgeführt wird.

Sehr toll fand ich den Überblick bzw. Vergleich von Solr vs. Datenbank (MySQL). Während mir detailreiche Erklärungen zu zahllosen Funktionen 
einer Software, die ich mit grosser Wahrscheinlichkeit auf dieser Ebene nie bedienen werde, sehr viel Geduld abverlangen, kann ich mit 
vogelperspektivischen Erläuterungen sehr viel mehr anfangen. Es war zudem eine gute Wiederholung zu Eigenschaften und Funktionsweisen von 
Datenbanken. Die Gegenüberstellung ist in den Folien sehr gut gemacht, darum erspare ich es mir, diese Folie hier abzutippen. Einzig die 
mangelnde Konsistenzprüfung bei Solr vs. Transaktionssicherheit bei MySQL finde ich hervorhebenswert. Ich hatte bis anhin nicht verstanden, 
dass Inkonsistenzen unter anderem auf einer bewussten Entscheidung zu Gunsten der Performance, bzw. Schnelligkeit basieren. Macht jetzt aber 
absolut Sinn. 

Die Erkenntnis aus der Übung Suchanfrage über Solr vs. Suchanfrage über VuFind halte ich hier kurz. Unterschiedliche Darstellung der Ergebnisse; 
VuFind ist um Längen anwender:innenfreundlicher, Solr liefert JSON-Format. Anzahl und Reihenfolge der Treffer war gleich. In Solr wird der 
gesamte Datensatz dargestellt, VuFind filtert. Im Terminal war zu erkennen, dass die Abfrage unterschiedlich strukturiert sind. VuFind nimmt 
bspw. ein Relevanzranking vor, Solr nicht. Daran zeigt sich, dass VuFind Suchergebnisse durch zusätzliche Angaben aufwertet, Solr gewichtet jedes 
Feld gleich. That’s that.

Und zu guter Letzt und von langer Hand angekündigt, die Zusammenführung der Datensätze aus ArchivesSpace, Koha, DSpace und dem doaj-Sample… 
ganz unspektakulär, geht. Z.T. gibt es Übersetzungsschwierigkeiten, wenn gemäss der marc.properties ein Pflichtfeld leer ist, in diesem Fall 
die ID. Aber im Grossen und Ganzen ist diese Übersetzung möglich. Dass es Datenverluste gibt, haben wir bereits in anderen Konvertierungsschritten 
erfahren. EAD zu MARC21-XML z.B. Aber dafür haben wir ja bereits die vielen vorhergehenden Blogeinträge geschrieben. Mir ist einmal mehr klar, 
was Kirsten Jeude macht, aber ganz ehrlich, ich möchte mit ihr nicht tauschen.
